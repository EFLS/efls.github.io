<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HCI | Elias Storms</title>
    <link>https://www.eliasstorms.net/tag/hci/</link>
      <atom:link href="https://www.eliasstorms.net/tag/hci/index.xml" rel="self" type="application/rss+xml" />
    <description>HCI</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2023 Elias Storms</copyright><lastBuildDate>Fri, 11 Nov 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.eliasstorms.net/media/icon_hu30740375d135df8f89c11012417564b7_13611_512x512_fill_lanczos_center_3.png</url>
      <title>HCI</title>
      <link>https://www.eliasstorms.net/tag/hci/</link>
    </image>
    
    <item>
      <title>&#39;Transparency is Meant for Control&#39; and Vice Versa: Learning from Co-designing and Evaluating Algorithmic News Recommenders</title>
      <link>https://www.eliasstorms.net/publication/storms-2022b/</link>
      <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://www.eliasstorms.net/publication/storms-2022b/</guid>
      <description>&lt;p&gt;Publication for CSCW 2022&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Algorithmic systems that recommend content often lack transparency
about how they come to their suggestions. One area in which
recommender systems are increasingly prevalent is online news
distribution. In this paper, we explore how a lack of transparency of
(news) recommenders can be tackled by involving users in the design of
interface elements. In the context of automated decision-making,
legislative frameworks such as the GDPR in Europe introduce a specific
conception of transparency, granting &amp;lsquo;data subjects&amp;rsquo; specific rights
and imposing obligations on service providers. An important related
question is how people using personalized recommender systems relate
to the issue of transparency, not as legal data subjects but as users.
This paper builds upon a two-phase study on how users conceive of
transparency and related issues in the context of algorithmic news
recommenders. We organized co-design workshops to elicit participants&amp;rsquo;
&amp;lsquo;algorithmic imaginaries&amp;rsquo; and invited them to ideate interface
elements for increased transparency. This revealed the importance of
combining legible transparency features with features that increase
user control. We then conducted a qualitative evaluation of mock-up
prototypes to investigate users&amp;rsquo; preferences and concerns when dealing
with design features to increase transparency and control. Our
investigation illustrates how users&amp;rsquo; expectations and impressions of
news recommenders are closely related to their news reading practices.
On a broader level, we show how transparency and control are
conceptually intertwined. Transparency without control leaves users
frustrated. Conversely, without a basic level of transparency into how
a system works, users remain unsure of the impact of controls.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving the Debate: Interface elements that enhance civility and relevance in online news comments</title>
      <link>https://www.eliasstorms.net/publication/bossens-2021/</link>
      <pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://www.eliasstorms.net/publication/bossens-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Foregrounding Algorithms: Preparing Users for Co-design with Sensitizing Activities</title>
      <link>https://www.eliasstorms.net/publication/alvarado-2020/</link>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://www.eliasstorms.net/publication/alvarado-2020/</guid>
      <description>&lt;p&gt;Paper presented at the NordiCHI 2020 conference.&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Algorithms are present in many of our everyday activities.
However, there is generally low awareness of their presence among users, and there are various conceptualizations to define them.
Additionally, algorithms are often both complex and opaque.
These characteristics raise challenges when applying co-design activities to the interaction design of algorithms.
We argue that researchers can overcome these challenges by developing sensitizing activities: activities that foreground the presence of algorithms, thus raising algorithmic awareness and a shared understanding, without influencing their initial experiences and expectations.
We share how we applied sensitizing activities in two case studies: sensitizing interviews, and diary studies together with two-phase workshops.
We share our experiences applying these techniques to overcome the challenges of low algorithmic awareness and multiple algorithmic understandings of participants.
Finally, we offer recommendations for researchers and practitioners when applying sensitizing activities in this design context and invite further methodological discussion on this challenging topic.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Actor-Network Theory in the Investigation of Algorithms</title>
      <link>https://www.eliasstorms.net/publication/storms-2019b/</link>
      <pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://www.eliasstorms.net/publication/storms-2019b/</guid>
      <description>&lt;p&gt;Paper accepted for the workshop
&lt;a href=&#34;https://authentic.sice.indiana.edu/philosophy-hci-workshop/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;lsquo;Standing on the Shoulders of Giants: Exploring the Intersection of Philosophy and HCI&amp;rsquo;&lt;/a&gt;
at the CHI 2019 conference in Glasgow.&lt;/p&gt;
&lt;p&gt;This draft connects &lt;em&gt;Actor-Network Theory&lt;/em&gt; and Human-Computer Interaction, reflecting on ongoing research on algorithmic ranking and selection.
It is very much a &lt;em&gt;working paper&lt;/em&gt;, and even though work on it has stalled, I am still interested in turning it into a full article at some point in the future.&lt;/p&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;This short paper, a submission for the HCI workshop &amp;lsquo;Standing on the Shoulders of Giants&amp;rsquo;, looks at scholarly studies of the presence of algorithmic selection in everyday life and how existing research benefits from and is connected to Actor-Network Theory (ANT). The paper then suggests that the empirical and philosophical strengths of ANT could benefit not just algorithms, but the broader field of HCI. With this exercise, this submission touches upon multiple key topics of the workshop. Most prominently, the paper addresses topics 2 and 6 by suggesting how ANT could connect to existing debates on, for example, &amp;lsquo;post-userism&amp;rsquo;. Also topic 5 is relevant, since the rather obscure philosophical underpinnings of ANT need to be made more accessible if we hope to make its approach useful for HCI.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
